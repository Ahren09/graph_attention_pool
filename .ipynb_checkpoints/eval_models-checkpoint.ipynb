{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.segmentation import slic\n",
    "import scipy.ndimage\n",
    "import scipy.spatial\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import datasets\n",
    "from chebygin import ChebyGIN\n",
    "from extract_superpixels import process_image\n",
    "from graphdata import comput_adjacency_matrix_images\n",
    "from utils import list_to_torch, data_to_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST-75sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "checkpoints_dir = './checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebyGINLayer torch.Size([4, 20]) tensor([0.6285, 0.5915, 0.4933, 0.5712], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([64, 16]) tensor([0.7078, 0.6896, 0.6898, 0.5610, 0.5307, 0.5662, 0.6105, 0.5552, 0.4937,\n",
      "        0.5751], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([512, 256]) tensor([0.5936, 0.5873, 0.5691, 0.5674, 0.5658, 0.5896, 0.5857, 0.5814, 0.5751,\n",
      "        0.5818], grad_fn=<SliceBackward>)\n",
      "ChebyGIN(\n",
      "  (graph_layers): Sequential(\n",
      "    (0): ChebyGINLayer(in_features=5, out_features=4, K=4, n_hidden=0, aggregation=mean)\n",
      "    fc=Sequential(\n",
      "      (0): Linear(in_features=20, out_features=4, bias=True)\n",
      "      (1): ReLU(inplace)\n",
      "    )\n",
      "    (1): ChebyGINLayer(in_features=4, out_features=64, K=4, n_hidden=0, aggregation=mean)\n",
      "    fc=Sequential(\n",
      "      (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "      (1): ReLU(inplace)\n",
      "    )\n",
      "    (2): ChebyGINLayer(in_features=64, out_features=512, K=4, n_hidden=0, aggregation=mean)\n",
      "    fc=Sequential(\n",
      "      (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (1): ReLU(inplace)\n",
      "    )\n",
      "    (3): GraphReadout(max)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "state = torch.load('%s/checkpoint_mnist-75sp_ws13.cfs.uoguelph.ca_401193_epoch2_seed0000011.pth.tar' % checkpoints_dir)\n",
    "args = state['args']\n",
    "model = ChebyGIN(in_features=5,\n",
    "                 out_features=10,\n",
    "                 filters=args.filters,\n",
    "                 K=args.filter_scale,\n",
    "                 n_hidden=args.n_hidden,\n",
    "                 aggregation=args.aggregation,\n",
    "                 dropout=args.dropout,\n",
    "                 readout=args.readout,\n",
    "                 pool=args.pool,\n",
    "                 pool_arch=args.pool_arch)\n",
    "print(model)\n",
    "model.load_state_dict(state['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.MNIST(data_dir, train=False, download=True)\n",
    "images = data.test_data.numpy()\n",
    "targets = data.test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image=0/10, shape=(28, 28, 1), min=0.00, max=1.00, n_sp=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/mlrg/bknyazev/anaconda2/envs/py3/lib/python3.6/site-packages/skimage/segmentation/slic_superpixels.py:156: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  segments_z = grid_z[slices]\n",
      "/export/mlrg/bknyazev/anaconda2/envs/py3/lib/python3.6/site-packages/skimage/segmentation/slic_superpixels.py:157: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  segments_y = grid_y[slices]\n",
      "/export/mlrg/bknyazev/anaconda2/envs/py3/lib/python3.6/site-packages/skimage/segmentation/slic_superpixels.py:158: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  segments_x = grid_x[slices]\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<built-in method eq of Tensor object at 0x7f59a049b510> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: bool value of Tensor with more than one value is ambiguous",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c5e75806fc46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'N_nodes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mN_nodes\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m: <built-in method eq of Tensor object at 0x7f59a049b510> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "mn = 0.11\n",
    "sd = 0.27\n",
    "args.n_sp = 75\n",
    "args.compactness = 0.25\n",
    "args.split = 'test'\n",
    "args.dataset = 'mnist'\n",
    "n_images = 10\n",
    "pred = []\n",
    "for i in range(n_images):\n",
    "    sp_intensity, sp_coord, sp_order, superpixels = process_image((images[i], i, n_images, args))\n",
    "    x = torch.from_numpy(np.pad(np.concatenate((sp_intensity, sp_coord), axis=1), \n",
    "                                ((0, 0), (2, 0)), 'edge')).unsqueeze(0)\n",
    "    N_nodes = x.shape[0]\n",
    "    A = torch.from_numpy(comput_adjacency_matrix_images(sp_coord)).float().unsqueeze(0)\n",
    "    y = model([x, A, torch.ones(1, N_nodes), -1, {'N_nodes': N_nodes}])[0]\n",
    "    pred.append(torch.argmax(y).item())\n",
    "    print(np.mean(np.equal(np.array(pred), targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 21.2983, -42.4245,  -6.2774,  -4.1152, -11.8668, -12.1466, -21.0363,\n",
       "           0.5697,   1.0573,   5.8848]], grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
