{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from skimage.segmentation import slic\n",
    "import scipy.ndimage\n",
    "import scipy.spatial\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import datasets\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from chebygin import ChebyGIN\n",
    "from extract_superpixels import process_image\n",
    "from graphdata import comput_adjacency_matrix_images\n",
    "from train_test import load_save_noise\n",
    "from utils import list_to_torch, data_to_device, normalize_zero_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRIANGLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Adj_matrices', 'GT_attn', 'graph_labels', 'N_edges', 'Max_degree'])\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/scratch/ssd/data/graph_attention_pool/'\n",
    "checkpoints_dir = '../checkpoints'\n",
    "device = 'cuda'\n",
    "\n",
    "with open('%s/random_graphs_triangles_test.pkl' % data_dir, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "print(data.keys())\n",
    "targets = torch.from_numpy(data['graph_labels']).long()\n",
    "Node_degrees = [np.sum(A, 1).astype(np.int32) for A in data['Adj_matrices']]\n",
    "\n",
    "feature_dim = data['Max_degree'] + 1\n",
    "node_features = []\n",
    "for i in range(len(data['Adj_matrices'])):\n",
    "    N = data['Adj_matrices'][i].shape[0]\n",
    "    D_onehot = np.zeros((N, feature_dim ))\n",
    "    D_onehot[np.arange(N), Node_degrees[i]] = 1\n",
    "    node_features.append(D_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acc(pred):\n",
    "    n = len(pred)\n",
    "    return torch.mean((torch.stack(pred).view(n) == targets[:len(pred)].view(n)).float()).item() * 100\n",
    "\n",
    "def test(model, index, show_img=False):    \n",
    "    N_nodes = data['Adj_matrices'][index].shape[0]\n",
    "    mask = torch.ones(1, N_nodes, dtype=torch.uint8)\n",
    "    x = torch.from_numpy(node_features[index]).unsqueeze(0).float() \n",
    "    A = torch.from_numpy(data['Adj_matrices'][index].astype(np.float32)).float().unsqueeze(0)\n",
    "    y, other_outputs = model(data_to_device([x, A, mask, -1, {'N_nodes': torch.zeros(1, 1) + N_nodes}], \n",
    "                                            device))    \n",
    "    y = y.round().long().data.cpu()[0][0]\n",
    "    alpha = other_outputs['alpha'][0].data.cpu() if 'alpha' in other_outputs else []        \n",
    "    return y, alpha\n",
    "\n",
    "\n",
    "# This function returns predictions for the entire clean and noise test sets\n",
    "def get_predictions(model_path):\n",
    "    state = torch.load(model_path)\n",
    "    args = state['args']\n",
    "    model = ChebyGIN(in_features=14,\n",
    "                     out_features=1,\n",
    "                     filters=args.filters,\n",
    "                     K=args.filter_scale,\n",
    "                     n_hidden=args.n_hidden,\n",
    "                     aggregation=args.aggregation,\n",
    "                     dropout=args.dropout,\n",
    "                     readout=args.readout,\n",
    "                     pool=args.pool,\n",
    "                     pool_arch=args.pool_arch)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    model = model.eval().to(device)\n",
    "#     print(model)    \n",
    "\n",
    "    # Get predictions\n",
    "    pred, alpha = [], []\n",
    "    for index in range(len(data['Adj_matrices'])):\n",
    "        y = test(model, index, index == 0)\n",
    "        pred.append(y[0])\n",
    "        alpha.append(y[1])\n",
    "        if len(pred) % 1000 == 0:\n",
    "            print('{}/{}, acc on the combined test set={:.2f}%'.format(len(pred), len(data['Adj_matrices']), acc(pred)))\n",
    "    return pred, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weakly-supervised attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebyGINLayer torch.Size([64, 98]) tensor([0.5568, 0.5545, 0.5580, 0.5656, 0.5318, 0.5698, 0.5655, 0.5937, 0.6087,\n",
      "        0.5437], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([32, 128]) tensor([0.5730, 0.5968, 0.5778, 0.5940, 0.5981, 0.5787, 0.5619, 0.5798, 0.5741,\n",
      "        0.5833], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([32, 64]) tensor([0.5703, 0.5380, 0.5825, 0.5836, 0.5649, 0.5537, 0.6568, 0.6129, 0.6161,\n",
      "        0.5258], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([1, 64]) tensor([0.5634], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([64, 448]) tensor([0.5923, 0.5840, 0.5608, 0.5615, 0.5799, 0.5668, 0.5924, 0.5840, 0.5709,\n",
      "        0.5637], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([32, 128]) tensor([0.5606, 0.5821, 0.5540, 0.5596, 0.6033, 0.6147, 0.5738, 0.5865, 0.5981,\n",
      "        0.5800], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([32, 64]) tensor([0.5938, 0.6073, 0.5995, 0.5230, 0.6091, 0.6070, 0.5901, 0.5752, 0.5594,\n",
      "        0.5499], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([1, 64]) tensor([0.6102], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([64, 448]) tensor([0.5877, 0.5797, 0.5591, 0.5688, 0.5758, 0.5645, 0.5483, 0.5846, 0.5883,\n",
      "        0.5961], grad_fn=<SliceBackward>)\n",
      "1000/10000, acc on the combined test set=83.00%\n",
      "2000/10000, acc on the combined test set=76.30%\n",
      "3000/10000, acc on the combined test set=72.23%\n",
      "4000/10000, acc on the combined test set=68.73%\n",
      "5000/10000, acc on the combined test set=66.82%\n",
      "6000/10000, acc on the combined test set=59.90%\n",
      "7000/10000, acc on the combined test set=55.04%\n",
      "8000/10000, acc on the combined test set=51.60%\n",
      "9000/10000, acc on the combined test set=49.02%\n",
      "10000/10000, acc on the combined test set=46.69%\n"
     ]
    }
   ],
   "source": [
    "pred, alpha = get_predictions('%s/checkpoint_triangles_230187_epoch100_seed0000111.pth.tar' % checkpoints_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
