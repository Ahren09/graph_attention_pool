{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from skimage.segmentation import slic\n",
    "import scipy.ndimage\n",
    "import scipy.spatial\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import datasets\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from chebygin import ChebyGIN\n",
    "from extract_superpixels import process_image\n",
    "from graphdata import comput_adjacency_matrix_images\n",
    "from train_test import load_save_noise\n",
    "from utils import list_to_torch, data_to_device, normalize_zero_one\n",
    "import imageio\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Adj_matrices', 'GT_attn', 'graph_labels', 'N_edges', 'Max_degree'])\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../data'\n",
    "checkpoints_dir = '../checkpoints'\n",
    "device = 'cuda'\n",
    "\n",
    "data_file = '/scratch/ssd/data/graph_attention_pool/random_graphs_triangles_test.pkl'\n",
    "with open(data_file, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "print(data.keys())\n",
    "targets = torch.from_numpy(data['graph_labels']).long()\n",
    "Node_degrees = [np.sum(A, 1).astype(np.int32) for A in data['Adj_matrices']]\n",
    "\n",
    "feature_dim = data['Max_degree'] + 1\n",
    "node_features = []\n",
    "for i in range(len(data['Adj_matrices'])):\n",
    "    N = data['Adj_matrices'][i].shape[0]\n",
    "    D_onehot = np.zeros((N, feature_dim ))\n",
    "    D_onehot[np.arange(N), Node_degrees[i]] = 1\n",
    "    node_features.append(D_onehot)\n",
    "\n",
    "edgecolors = [0.3, 0.3, 0.3, 0.1]\n",
    "edgewidth = 0.5\n",
    "\n",
    "def get_pooled_graph(A_org, pos, bool_ind):\n",
    "    idx = np.where(bool_ind)[0]\n",
    "    A = A_org.copy()\n",
    "    A = A[:,idx][idx, :]\n",
    "    G = nx.from_numpy_array(A)\n",
    "    pos_new = {}\n",
    "    for j in range(len(idx)):\n",
    "        pos_new[j] = pos[idx[j]] #+ np.array([0, -0.1])\n",
    "        \n",
    "    idx_d = np.where(~bool_ind)[0]\n",
    "    #print(len(idx_d), bool_ind, len(idx))\n",
    "    G_dummy = nx.from_numpy_array(A_org[:,idx_d][idx_d, :])\n",
    "    pos_dummy = {}\n",
    "    for j in range(len(idx_d)):\n",
    "        pos_dummy[j] = pos[idx_d[j]]        \n",
    "    nx.draw_networkx_nodes(G_dummy, pos_dummy, node_color=np.ones((len(pos_dummy), 3)), node_size=0,\n",
    "                          alpha=0)\n",
    "    \n",
    "    #draw_graph(G, pos_new, alpha[idx], cmap, vmin, vmax, ticks)\n",
    "    return G, pos_new, idx\n",
    "    \n",
    "    \n",
    "def draw_graph_triangles(data, ind, alpha, alpha_unsup, alpha_sup, cm='Purples', layout='spring', node_size=300, edgewidth_=None):\n",
    "    A = data['Adj_matrices'][ind]\n",
    "    G = nx.from_numpy_array(A)    \n",
    "    gt_attn = data['GT_attn'][ind].squeeze()\n",
    "    gt_attn = gt_attn / (float(np.sum(gt_attn)) + 1e-7)\n",
    "    fig = plt.figure()\n",
    "    cmap = plt.cm.get_cmap(cm, len(gt_attn))\n",
    "    vmin = gt_attn.min()\n",
    "    vmax = gt_attn.max()\n",
    "    if layout == 'spring':\n",
    "        pos = nx.spring_layout(G)\n",
    "    elif layout == 'shell':\n",
    "        pos = nx.shell_layout(G)\n",
    "    else:\n",
    "        raise NotImplementedError(layout)\n",
    "    if edgewidth_ is None:\n",
    "        edgewidth_ = edgewidth\n",
    "    \n",
    "    # GT graph\n",
    "    nx.draw_networkx(G, pos, node_color=gt_attn, with_labels=False, node_size=node_size,\n",
    "                    width=edgewidth_, edgecolors=edgecolors, cmap=cmap, vmin=vmin, vmax=vmax)  \n",
    "    plt.axis('off')\n",
    "    plt.savefig('images/%d_gt.png' % ind)\n",
    "    plt.show()\n",
    "    G_pooled, pos_pooled, idx = get_pooled_graph(A, pos, gt_attn > 0)\n",
    "    nx.draw_networkx(G_pooled, pos_pooled, node_color=gt_attn.squeeze()[idx], with_labels=False, \n",
    "                     node_size=node_size, width=edgewidth_, \n",
    "                     edgecolors=edgecolors, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    plt.axis('off')\n",
    "    plt.savefig('images/%d_gt_pooled.png' % ind)\n",
    "    plt.show()\n",
    "    \n",
    "    nx.draw_networkx(G, pos, node_color=alpha, with_labels=False, node_size=node_size,\n",
    "                    width=edgewidth_, edgecolors=edgecolors, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    plt.axis('off')\n",
    "    plt.savefig('images/%d_pred.png' % ind)\n",
    "    plt.show()\n",
    "    \n",
    "    G_pooled, pos_pooled, idx = get_pooled_graph(A, pos, alpha > 0.01)\n",
    "    nx.draw_networkx(G_pooled, pos_pooled, node_color=alpha.squeeze()[idx], with_labels=False, \n",
    "                     node_size=node_size, width=edgewidth_, \n",
    "                     edgecolors=edgecolors, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    plt.axis('off')\n",
    "    plt.savefig('images/%d_pred_pooled.png' % ind)\n",
    "    plt.show()\n",
    "    \n",
    "    nx.draw_networkx(G, pos, node_color=alpha_unsup, with_labels=False, node_size=node_size,\n",
    "                    width=edgewidth_, edgecolors=edgecolors, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    plt.axis('off')\n",
    "    plt.savefig('images/%d_pred_unsup.png' % ind)\n",
    "    plt.show()\n",
    "    \n",
    "    G_pooled, pos_pooled, idx = get_pooled_graph(A, pos, alpha > 0.0001)\n",
    "    nx.draw_networkx(G_pooled, pos_pooled, node_color=alpha_unsup.squeeze()[idx], with_labels=False, \n",
    "                     node_size=node_size, width=edgewidth_, \n",
    "                     edgecolors=edgecolors, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    plt.axis('off')\n",
    "    plt.savefig('images/%d_pred_unsup_pooled.png' % ind)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    nx.draw_networkx(G, pos, node_color=alpha_sup, with_labels=False, node_size=node_size,\n",
    "                    width=edgewidth_, edgecolors=edgecolors, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    plt.axis('off')\n",
    "    plt.savefig('images/%d_pred_sup.png' % ind)\n",
    "    plt.show()\n",
    "    \n",
    "    G_pooled, pos_pooled, idx = get_pooled_graph(A, pos, alpha > 0.001)\n",
    "    nx.draw_networkx(G_pooled, pos_pooled, node_color=alpha_sup.squeeze()[idx], with_labels=False, \n",
    "                     node_size=node_size, width=edgewidth_, \n",
    "                     edgecolors=edgecolors, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    plt.axis('off')\n",
    "    plt.savefig('images/%d_pred_sup_pooled.png' % ind)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acc(pred):\n",
    "    n = len(pred)\n",
    "    #print(n)\n",
    "    return torch.mean((torch.stack(pred).view(n) == targets[:len(pred)].view(n)).float()).item() * 100\n",
    "\n",
    "def test(model, index, show_img=False):    \n",
    "    #['Adj_matrices', 'GT_attn', 'graph_labels', 'N_edges', 'Max_degree']\n",
    "    \n",
    "    N_nodes = data['Adj_matrices'][index].shape[0]\n",
    "    mask = torch.ones(1, N_nodes, dtype=torch.uint8)\n",
    "    x = torch.from_numpy(node_features[index]).unsqueeze(0).float() \n",
    "    A = torch.from_numpy(data['Adj_matrices'][index].astype(np.float32)).float().unsqueeze(0)\n",
    "    #print(A.shape, A)\n",
    "    y, other_outputs = model(data_to_device([x, A, mask, -1, {'N_nodes': torch.zeros(1, 1) + N_nodes}], \n",
    "                                            device))\n",
    "    \n",
    "    y_clean = y.round().long().data.cpu()[0][0]\n",
    "    #print(y_clean)\n",
    "    alpha_clean = other_outputs['alpha'][0].data.cpu() if 'alpha' in other_outputs else []\n",
    "        \n",
    "    return y_clean, alpha_clean\n",
    "\n",
    "\n",
    "# This function returns predictions for the entire clean and noise test sets\n",
    "def get_predictions(model_path):\n",
    "    state = torch.load(model_path)\n",
    "    args = state['args']\n",
    "    model = ChebyGIN(in_features=14,\n",
    "                     out_features=1,\n",
    "                     filters=args.filters,\n",
    "                     K=args.filter_scale,\n",
    "                     n_hidden=args.n_hidden,\n",
    "                     aggregation=args.aggregation,\n",
    "                     dropout=args.dropout,\n",
    "                     readout=args.readout,\n",
    "                     pool=args.pool,\n",
    "                     pool_arch=args.pool_arch)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    model = model.eval().to(device)\n",
    "    print(model)    \n",
    "\n",
    "    # Get predictions\n",
    "    pred, alpha = [], []\n",
    "    for index in range(len(data['Adj_matrices'])):\n",
    "        y = test(model, index, index == 0)\n",
    "        pred.append(y[0])\n",
    "        alpha.append(y[1])\n",
    "        if len(pred) % 100 == 0:\n",
    "            print('{}/{}, acc clean={:.2f}%,'.format(len(pred), len(data['Adj_matrices']), acc(pred)))\n",
    "    return pred, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebyGINLayer torch.Size([64, 98]) tensor([0.5373, 0.5972, 0.5666, 0.5730, 0.5695, 0.5734, 0.5870, 0.6046, 0.5682,\n",
      "        0.5942], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([32, 128]) tensor([0.5203, 0.6058, 0.5815, 0.5773, 0.5477, 0.5762, 0.6436, 0.5717, 0.6062,\n",
      "        0.5599], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([32, 64]) tensor([0.5974, 0.5235, 0.6033, 0.5646, 0.5445, 0.5571, 0.6173, 0.6421, 0.5832,\n",
      "        0.5658], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([1, 64]) tensor([0.5256], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([64, 448]) tensor([0.5915, 0.5470, 0.5900, 0.5749, 0.5824, 0.5810, 0.5622, 0.5880, 0.5768,\n",
      "        0.5656], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([32, 128]) tensor([0.5744, 0.6069, 0.5795, 0.5684, 0.5997, 0.5734, 0.5859, 0.5607, 0.5622,\n",
      "        0.5676], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([32, 64]) tensor([0.5853, 0.5836, 0.6154, 0.6380, 0.5484, 0.4919, 0.6253, 0.6428, 0.5296,\n",
      "        0.5580], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([1, 64]) tensor([0.6184], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([64, 448]) tensor([0.5697, 0.5689, 0.5729, 0.5709, 0.5813, 0.5777, 0.6006, 0.5623, 0.5711,\n",
      "        0.5866], grad_fn=<SliceBackward>)\n",
      "ChebyGIN(\n",
      "  (graph_layers): Sequential(\n",
      "    (0): ChebyGINLayer(in_features=14, out_features=64, K=7, n_hidden=64, aggregation=sum)\n",
      "    fc=Sequential(\n",
      "      (0): Linear(in_features=98, out_features=64, bias=True)\n",
      "      (1): ReLU(inplace)\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU(inplace)\n",
      "    )\n",
      "    (1): AttentionPooling(pool_type=['attn', 'sup', 'threshold', '0.01'], pool_arch=['gnn', 'curr'], topk=False, kl_weight=None, proj=ChebyGIN(\n",
      "      (graph_layers): Sequential(\n",
      "        (0): ChebyGINLayer(in_features=64, out_features=32, K=2, n_hidden=0, aggregation=sum)\n",
      "        fc=Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (1): ChebyGINLayer(in_features=32, out_features=32, K=2, n_hidden=0, aggregation=sum)\n",
      "        fc=Sequential(\n",
      "          (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (2): ChebyGINLayer(in_features=32, out_features=1, K=2, n_hidden=0, aggregation=sum)\n",
      "        fc=Sequential(\n",
      "          (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "        )\n",
      "      )\n",
      "    ))\n",
      "    (2): ChebyGINLayer(in_features=64, out_features=64, K=7, n_hidden=64, aggregation=sum)\n",
      "    fc=Sequential(\n",
      "      (0): Linear(in_features=448, out_features=64, bias=True)\n",
      "      (1): ReLU(inplace)\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU(inplace)\n",
      "    )\n",
      "    (3): AttentionPooling(pool_type=['attn', 'sup', 'threshold', '0.01'], pool_arch=['gnn', 'curr'], topk=False, kl_weight=None, proj=ChebyGIN(\n",
      "      (graph_layers): Sequential(\n",
      "        (0): ChebyGINLayer(in_features=64, out_features=32, K=2, n_hidden=0, aggregation=sum)\n",
      "        fc=Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (1): ChebyGINLayer(in_features=32, out_features=32, K=2, n_hidden=0, aggregation=sum)\n",
      "        fc=Sequential(\n",
      "          (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (2): ChebyGINLayer(in_features=32, out_features=1, K=2, n_hidden=0, aggregation=sum)\n",
      "        fc=Sequential(\n",
      "          (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "        )\n",
      "      )\n",
      "    ))\n",
      "    (4): ChebyGINLayer(in_features=64, out_features=64, K=7, n_hidden=64, aggregation=sum)\n",
      "    fc=Sequential(\n",
      "      (0): Linear(in_features=448, out_features=64, bias=True)\n",
      "      (1): ReLU(inplace)\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU(inplace)\n",
      "    )\n",
      "    (5): GraphReadout(max)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "100/10000, acc clean=90.00%,\n",
      "200/10000, acc clean=89.00%,\n",
      "300/10000, acc clean=87.33%,\n",
      "400/10000, acc clean=88.25%,\n",
      "500/10000, acc clean=88.60%,\n",
      "600/10000, acc clean=86.50%,\n",
      "700/10000, acc clean=85.57%,\n",
      "800/10000, acc clean=85.50%,\n",
      "900/10000, acc clean=84.33%,\n",
      "1000/10000, acc clean=83.00%,\n",
      "1100/10000, acc clean=81.73%,\n",
      "1200/10000, acc clean=80.17%,\n",
      "1300/10000, acc clean=80.08%,\n",
      "1400/10000, acc clean=79.50%,\n",
      "1500/10000, acc clean=78.73%,\n",
      "1600/10000, acc clean=78.00%,\n",
      "1700/10000, acc clean=77.59%,\n",
      "1800/10000, acc clean=77.39%,\n",
      "1900/10000, acc clean=76.95%,\n",
      "2000/10000, acc clean=76.30%,\n",
      "2100/10000, acc clean=75.76%,\n",
      "2200/10000, acc clean=75.68%,\n",
      "2300/10000, acc clean=75.57%,\n",
      "2400/10000, acc clean=75.04%,\n",
      "2500/10000, acc clean=74.68%,\n",
      "2600/10000, acc clean=74.31%,\n",
      "2700/10000, acc clean=73.63%,\n",
      "2800/10000, acc clean=73.32%,\n",
      "2900/10000, acc clean=72.41%,\n",
      "3000/10000, acc clean=72.23%,\n",
      "3100/10000, acc clean=71.77%,\n",
      "3200/10000, acc clean=71.28%,\n",
      "3300/10000, acc clean=70.82%,\n",
      "3400/10000, acc clean=70.62%,\n",
      "3500/10000, acc clean=70.29%,\n",
      "3600/10000, acc clean=70.03%,\n",
      "3700/10000, acc clean=69.54%,\n",
      "3800/10000, acc clean=69.29%,\n",
      "3900/10000, acc clean=68.95%,\n",
      "4000/10000, acc clean=68.73%,\n",
      "4100/10000, acc clean=68.22%,\n",
      "4200/10000, acc clean=67.79%,\n",
      "4300/10000, acc clean=67.53%,\n",
      "4400/10000, acc clean=67.34%,\n",
      "4500/10000, acc clean=67.18%,\n",
      "4600/10000, acc clean=67.02%,\n",
      "4700/10000, acc clean=66.98%,\n",
      "4800/10000, acc clean=66.92%,\n",
      "4900/10000, acc clean=66.80%,\n",
      "5000/10000, acc clean=66.82%,\n",
      "5100/10000, acc clean=66.08%,\n",
      "5200/10000, acc clean=65.38%,\n",
      "5300/10000, acc clean=64.60%,\n",
      "5400/10000, acc clean=63.70%,\n",
      "5500/10000, acc clean=63.02%,\n",
      "5600/10000, acc clean=62.37%,\n",
      "5700/10000, acc clean=61.70%,\n",
      "5800/10000, acc clean=61.05%,\n",
      "5900/10000, acc clean=60.49%,\n",
      "6000/10000, acc clean=59.90%,\n",
      "6100/10000, acc clean=59.34%,\n",
      "6200/10000, acc clean=58.84%,\n",
      "6300/10000, acc clean=58.32%,\n",
      "6400/10000, acc clean=57.78%,\n",
      "6500/10000, acc clean=57.34%,\n",
      "6600/10000, acc clean=56.79%,\n",
      "6700/10000, acc clean=56.37%,\n",
      "6800/10000, acc clean=55.82%,\n",
      "6900/10000, acc clean=55.39%,\n",
      "7000/10000, acc clean=55.04%,\n",
      "7100/10000, acc clean=54.69%,\n",
      "7200/10000, acc clean=54.35%,\n",
      "7300/10000, acc clean=53.92%,\n",
      "7400/10000, acc clean=53.54%,\n",
      "7500/10000, acc clean=53.17%,\n",
      "7600/10000, acc clean=52.84%,\n",
      "7700/10000, acc clean=52.48%,\n",
      "7800/10000, acc clean=52.17%,\n",
      "7900/10000, acc clean=51.84%,\n",
      "8000/10000, acc clean=51.60%,\n",
      "8100/10000, acc clean=51.22%,\n",
      "8200/10000, acc clean=50.95%,\n",
      "8300/10000, acc clean=50.70%,\n",
      "8400/10000, acc clean=50.50%,\n",
      "8500/10000, acc clean=50.24%,\n",
      "8600/10000, acc clean=50.02%,\n",
      "8700/10000, acc clean=49.78%,\n",
      "8800/10000, acc clean=49.52%,\n",
      "8900/10000, acc clean=49.24%,\n",
      "9000/10000, acc clean=49.02%,\n",
      "9100/10000, acc clean=48.80%,\n",
      "9200/10000, acc clean=48.53%,\n",
      "9300/10000, acc clean=48.32%,\n",
      "9400/10000, acc clean=48.07%,\n",
      "9500/10000, acc clean=47.84%,\n",
      "9600/10000, acc clean=47.56%,\n",
      "9700/10000, acc clean=47.26%,\n",
      "9800/10000, acc clean=47.01%,\n",
      "9900/10000, acc clean=46.90%,\n",
      "10000/10000, acc clean=46.69%,\n"
     ]
    }
   ],
   "source": [
    "pred, alpha = get_predictions('%s/checkpoint_triangles_230187_epoch100_seed0000111.pth.tar' % checkpoints_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebyGINLayer torch.Size([64, 98]) tensor([0.5786, 0.5730, 0.5617, 0.5878, 0.5461, 0.5948, 0.5906, 0.5912, 0.5335,\n",
      "        0.5677], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([32, 128]) tensor([0.5745, 0.5512, 0.6142, 0.6060, 0.5642, 0.6059, 0.5804, 0.5554, 0.6017,\n",
      "        0.5770], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([32, 64]) tensor([0.5932, 0.5593, 0.5627, 0.6019, 0.5524, 0.6440, 0.5917, 0.6590, 0.6078,\n",
      "        0.6346], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([1, 64]) tensor([0.5725], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([64, 448]) tensor([0.5852, 0.5747, 0.5673, 0.5769, 0.5656, 0.5823, 0.5840, 0.5799, 0.5815,\n",
      "        0.5818], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([32, 128]) tensor([0.6090, 0.5671, 0.5828, 0.5906, 0.6003, 0.5523, 0.5744, 0.5403, 0.5639,\n",
      "        0.5650], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([32, 64]) tensor([0.6284, 0.6083, 0.5712, 0.5842, 0.5590, 0.5947, 0.5660, 0.5510, 0.5604,\n",
      "        0.5742], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([1, 64]) tensor([0.6522], grad_fn=<SliceBackward>)\n",
      "ChebyGINLayer torch.Size([64, 448]) tensor([0.5753, 0.5883, 0.5793, 0.5571, 0.5435, 0.5798, 0.5854, 0.5797, 0.5592,\n",
      "        0.6031], grad_fn=<SliceBackward>)\n",
      "ChebyGIN(\n",
      "  (graph_layers): Sequential(\n",
      "    (0): ChebyGINLayer(in_features=14, out_features=64, K=7, n_hidden=64, aggregation=sum)\n",
      "    fc=Sequential(\n",
      "      (0): Linear(in_features=98, out_features=64, bias=True)\n",
      "      (1): ReLU(inplace)\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU(inplace)\n",
      "    )\n",
      "    (1): AttentionPooling(pool_type=['attn', 'unsup', 'threshold', '0.0001'], pool_arch=['gnn', 'curr'], topk=False, kl_weight=None, proj=ChebyGIN(\n",
      "      (graph_layers): Sequential(\n",
      "        (0): ChebyGINLayer(in_features=64, out_features=32, K=2, n_hidden=0, aggregation=sum)\n",
      "        fc=Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (1): ChebyGINLayer(in_features=32, out_features=32, K=2, n_hidden=0, aggregation=sum)\n",
      "        fc=Sequential(\n",
      "          (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (2): ChebyGINLayer(in_features=32, out_features=1, K=2, n_hidden=0, aggregation=sum)\n",
      "        fc=Sequential(\n",
      "          (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "        )\n",
      "      )\n",
      "    ))\n",
      "    (2): ChebyGINLayer(in_features=64, out_features=64, K=7, n_hidden=64, aggregation=sum)\n",
      "    fc=Sequential(\n",
      "      (0): Linear(in_features=448, out_features=64, bias=True)\n",
      "      (1): ReLU(inplace)\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU(inplace)\n",
      "    )\n",
      "    (3): AttentionPooling(pool_type=['attn', 'unsup', 'threshold', '0.0001'], pool_arch=['gnn', 'curr'], topk=False, kl_weight=None, proj=ChebyGIN(\n",
      "      (graph_layers): Sequential(\n",
      "        (0): ChebyGINLayer(in_features=64, out_features=32, K=2, n_hidden=0, aggregation=sum)\n",
      "        fc=Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (1): ChebyGINLayer(in_features=32, out_features=32, K=2, n_hidden=0, aggregation=sum)\n",
      "        fc=Sequential(\n",
      "          (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace)\n",
      "        )\n",
      "        (2): ChebyGINLayer(in_features=32, out_features=1, K=2, n_hidden=0, aggregation=sum)\n",
      "        fc=Sequential(\n",
      "          (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "        )\n",
      "      )\n",
      "    ))\n",
      "    (4): ChebyGINLayer(in_features=64, out_features=64, K=7, n_hidden=64, aggregation=sum)\n",
      "    fc=Sequential(\n",
      "      (0): Linear(in_features=448, out_features=64, bias=True)\n",
      "      (1): ReLU(inplace)\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU(inplace)\n",
      "    )\n",
      "    (5): GraphReadout(max)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "100/10000, acc clean=83.00%,\n",
      "200/10000, acc clean=86.50%,\n",
      "300/10000, acc clean=86.00%,\n",
      "400/10000, acc clean=83.50%,\n",
      "500/10000, acc clean=84.80%,\n",
      "600/10000, acc clean=83.83%,\n",
      "700/10000, acc clean=82.71%,\n",
      "800/10000, acc clean=82.63%,\n",
      "900/10000, acc clean=81.11%,\n",
      "1000/10000, acc clean=80.00%,\n",
      "1100/10000, acc clean=78.91%,\n",
      "1200/10000, acc clean=78.17%,\n",
      "1300/10000, acc clean=77.23%,\n",
      "1400/10000, acc clean=77.07%,\n",
      "1500/10000, acc clean=76.47%,\n",
      "1600/10000, acc clean=75.81%,\n",
      "1700/10000, acc clean=74.76%,\n",
      "1800/10000, acc clean=74.00%,\n",
      "1900/10000, acc clean=73.37%,\n",
      "2000/10000, acc clean=73.15%,\n",
      "2100/10000, acc clean=72.57%,\n",
      "2200/10000, acc clean=72.32%,\n",
      "2300/10000, acc clean=71.78%,\n",
      "2400/10000, acc clean=71.42%,\n",
      "2500/10000, acc clean=70.76%,\n",
      "2600/10000, acc clean=70.15%,\n",
      "2700/10000, acc clean=69.56%,\n",
      "2800/10000, acc clean=68.96%,\n",
      "2900/10000, acc clean=68.38%,\n",
      "3000/10000, acc clean=68.20%,\n",
      "3100/10000, acc clean=67.81%,\n",
      "3200/10000, acc clean=67.25%,\n",
      "3300/10000, acc clean=67.09%,\n",
      "3400/10000, acc clean=66.82%,\n",
      "3500/10000, acc clean=66.26%,\n",
      "3600/10000, acc clean=65.83%,\n",
      "3700/10000, acc clean=65.65%,\n",
      "3800/10000, acc clean=65.26%,\n",
      "3900/10000, acc clean=65.18%,\n",
      "4000/10000, acc clean=64.95%,\n",
      "4100/10000, acc clean=64.51%,\n",
      "4200/10000, acc clean=64.33%,\n",
      "4300/10000, acc clean=63.91%,\n",
      "4400/10000, acc clean=63.57%,\n",
      "4500/10000, acc clean=63.24%,\n",
      "4600/10000, acc clean=63.41%,\n",
      "4700/10000, acc clean=63.38%,\n",
      "4800/10000, acc clean=63.42%,\n",
      "4900/10000, acc clean=63.59%,\n",
      "5000/10000, acc clean=63.72%,\n",
      "5100/10000, acc clean=63.12%,\n",
      "5200/10000, acc clean=62.37%,\n",
      "5300/10000, acc clean=61.60%,\n",
      "5400/10000, acc clean=60.85%,\n",
      "5500/10000, acc clean=60.09%,\n",
      "5600/10000, acc clean=59.46%,\n",
      "5700/10000, acc clean=58.82%,\n",
      "5800/10000, acc clean=58.22%,\n",
      "5900/10000, acc clean=57.71%,\n",
      "6000/10000, acc clean=57.28%,\n",
      "6100/10000, acc clean=56.66%,\n",
      "6200/10000, acc clean=56.11%,\n",
      "6300/10000, acc clean=55.63%,\n",
      "6400/10000, acc clean=55.19%,\n",
      "6500/10000, acc clean=54.68%,\n",
      "6600/10000, acc clean=54.26%,\n",
      "6700/10000, acc clean=53.82%,\n",
      "6800/10000, acc clean=53.41%,\n",
      "6900/10000, acc clean=52.96%,\n"
     ]
    }
   ],
   "source": [
    "pred_unsup, alpha_unsup = get_predictions('%s/checkpoint_triangles_051609_epoch100_seed0000111.pth.tar' % checkpoints_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_sup, alpha_sup = get_predictions('%s/checkpoint_triangles_586710_epoch100_seed0000111.pth.tar' % checkpoints_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shapes = np.array([A.shape[0] for A in data['Adj_matrices']])\n",
    "# D = np.array([np.sum(A.sum(1) == 0) for A in data['Adj_matrices']])\n",
    "# idx = np.where((D == 0) & (data['graph_labels'] == 3))[0]\n",
    "# #print(len(idx))\n",
    "# for i, ind in enumerate(idx[:2]):    \n",
    "#     draw_graph_triangles(data, ind, 'Purples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for shape in np.unique(shapes[idx]):\n",
    "    ind = np.where((shapes == shape) & (D == 0) & (data['graph_labels'] == 3))[0][0]\n",
    "    draw_graph_triangles(data, ind, \n",
    "                         alpha[ind].numpy().squeeze(), \n",
    "                         alpha_unsup[ind].numpy().squeeze(), \n",
    "                         alpha_sup[ind].numpy().squeeze(),\n",
    "                         'Purples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for shape in np.unique(shapes[idx]):\n",
    "    ind = np.where((shapes == shape) & (D == 0) & (data['graph_labels'] == 3))[0][0]\n",
    "    im1 = Image.open('images/%d_gt.png' % ind)\n",
    "    im2 = Image.open('images/%d_gt_pooled.png' % ind)\n",
    "    im3 = Image.open('images/%d_pred_unsup.png' % ind)\n",
    "    im4 = Image.open('images/%d_pred_unsup_pooled.png' % ind)\n",
    "    im5 = Image.open('images/%d_pred.png' % ind)\n",
    "    im6 = Image.open('images/%d_pred_pooled.png' % ind)\n",
    "    im1 = np.concatenate((im1, im2), axis=1)\n",
    "    im2 = np.concatenate((im3, im4), axis=1)\n",
    "    im3 = np.concatenate((im5, im6), axis=1)\n",
    "    im = np.concatenate((im1, im2, im3), axis=0)\n",
    "    images.append(im)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imageio.mimsave('../data/triangles_animation.gif', images, format='GIF', duration=1.5)\n",
    "#imageio.mimsave('attn.gif', attn, format='GIF', duration=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 92)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes[idx].min(), shapes[idx].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
